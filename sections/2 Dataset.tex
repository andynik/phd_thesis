\chapter{Методи підготовки та синтезу математичних комбінаторних задач}
\label{sec:datasets}

\section{Способи підготовки даних}

Підготовка даних може здійснюватися за допомогою експертів-анотаторів або шляхом генерації синтетичних даних з використанням моделей. Анотація людиною забезпечує високу якість, але є більш ресурсозатратною та дорогою. Як зазначається у роботі MathGenie \cite{lu2024mathgeniegeneratingsyntheticdata}, генерація синтетичних даних за допомогою дозволяє збільшити набір навчальних даних та підвищити ефективність моделей. Це можливо за рахунок методів генерації різноманітних і коректних математичних задач із невеликого вхідного набору задач.

\section{Існуючі набори даних}

Існує багато наборів даних для оцінки математичних можливостей мовних моделей. Розглянемо деякі з них.

\subsection{Ранні набори даних}
Для надання розв'язку до певного типу задачі необхідно обробити та визначити основні елементи відповідних задач за допомогою методів обробки природної мови. Існує багато наборів даних, які використовуються для надання рішень до математичних текстових задач (MWP). Нижче наведені деякі з них, які використовувалися до 2016 року \cite{Nikolaiev202294}:

\begin{itemize}
    \item {Alg514} \cite{kushman-etal-2014-learning}: Набір даних, зібраний з веб-сайту спільноти для навчання algebra.com, містить 514 задач з лінійної алгебри з 28 шаблонами рівнянь.
    
    \item {AI2} \cite{hosseini-etal-2014-learning}: Містить 395 арифметичних текстових задач у один та кілька кроків розв'язання для учнів молодшої школи. Завдання можна розв'язати, використовуючи лише додавання та віднімання. Набір даних зібраний з двох веб-сайтів: math-aids.com та ixl.com.
    
    \item {Dolphin1878} \cite{shi-etal-2015-automatically}: Містить 1,878 числових текстових задач з 1,183 шаблонами рівнянь, отриманих з algebra.com та Yahoo! Answers.
    
    \item {DRAW} \cite{Upadhyay2015DRAWAC}: Містить 1,000 алгебраїчних текстових задач з algebra.com, кожна з яких анотована лінійними рівняннями.
    
    \item {SingleEQ} \cite{koncel2015parsing}: Набір даних містить арифметичні задачі у один та кілька кроків розв'язання та є збіркою задач з різних джерел, зокрема веб-сайтів math-aids.com, k5learning.com, ixl.com, а також деяких задач з набору даних AI2. Кожне завдання включає оператори множення, ділення, віднімання та додавання над невід'ємними раціональними числами.
    
    \item {Dolphin18K} \cite{huang-etal-2016-well}: Містить понад 18,000 анотованих математичних текстових задач. Даний набір був створений шляхом напівавтоматичного збору задач, систем рівнянь та розв'язків з веб-сторінок спільноти -- питання та відповіді. Вихідні дані включають набір у форматі $<text, question, answer>$ разом з додатковими деталями, які були зібрані з категорії ``математика'' на веб-сайті ``Yahoo! Answers''.
    
    \item {MAWPS} \cite{koncel-kedziorski-etal-2016-mawps}: Інший тестовий набір для арифметичних текстових задач з однією невідомою змінною. Його мета -- скласти набір даних різної складності з різних веб-сайтів. Операційно він поєднує опубліковані набори даних текстових задач, використані в AI2 та деякі інші. У зібраному наборі даних 2,373 питання.
    
    \item {Math23K} \cite{wang-etal-2017-deep}: Набір даних містить китайські математичні текстові задачі для учнів початкової школи, зібрані з кількох онлайн-освітніх веб-сайтів.

    \item {Ape210K} \cite{zhao2020ape210klargescaletemplaterichdataset}: Випущений у 2020 році, містить 210 тис. китайських математичних задач рівня початкової школи.
    
    \item {SVAMP} \cite{patel-etal-2021-nlp}: У 2021 році автори використали моделі Graph2Tree з RoBERTa, GTS з RoBERTa, LSTM Seq2Seq з RoBERTa, Transformer з RoBERTa на даних представленого набору SVAMP, який містив 1,000 задач з компіляцією рівнянь початкової школи, створених шляхом застосування ретельно підібраних варіацій до прикладів, взятих з існуючих наборів даних.
    \end{itemize}

\subsection{Найбільш поширені набори даних}

Цей розділ висвітлює широко використовувані набори даних, орієнтовані на оцінку математичних здібностей мовних моделей. GSM8K складається з базових математичних задач з покроковими розв'язаннями, що сприяє розвитку навичок вирішення початкових завдань. Набір MATH включає 12,500 олімпіадних задач, що потребують глибокого розуміння і складних міркувань, і використовується для тестування на моделях типу GPT-3. MMLU представляє собою різноманітний набір тем, включаючи математику, з запитаннями з множинним вибором відповідей. MiniF2F зосереджується на формальних математичних олімпіадних задачах для нейромережевих доведень теорем. FIMO пропонує формалізовані задачі для автоматизованого доведення теорем, демонструючи високу складність та наявність формальних доказів. Ці набори даних створюють основу для комплексного тестування мовних моделей в академічному і дослідницькому середовищі.

\begin{itemize}

    \item {GSM8K} \cite{cobbe2021trainingverifierssolvemath}: Містить 8 000 високоякісних математичних текстових задач початкового рівня з чіткими покроковими розв'язаннями, що вимагають 2-8 кроків для розв'язання.
    
    \item {MATH} \cite{hendrycks2021measuringmathematicalproblemsolving}: Містить 12,500 задач з математики олімпіадного рівня та покроковими розв'язаннями. Завдання вимагають глибокого розуміння математичних концепцій та складних міркувань.
    У 2021 році автори використали модель GPT-3 на основі набору MATH, який містить 12,500 задач з математичних змагань середніх шкіл, а також ASMP пре-тренувальний корпус, що складається з даних Khan Academy та Mathematica. AMPS містить понад 100 000 задач Khan Academy із покроковими розв’язаннями у форматі LaTeX, а також понад 5 мільйонів задач, згенерованих за допомогою скриптів Mathematica. Ці задачі базуються на 100 вручну розроблених модулях, що охоплюють такі теми, як конічні перерізи, оператори div, grad і curl, KL-дивергенція, власні значення, багатовиди та діофантові рівняння. У цілому AMPS містить 23 ГБ задач та розв'язань.
    
    \item {MMLU} \cite{hendrycks2021measuringmassivemultitasklanguage}: Складається з 57 предметів з відкритими запитаннями з множинним вибором відповідей, включаючи математику та суміжні дисципліни.
    
    \item {MiniF2F} \cite{zheng2022minif2fcrosssystembenchmarkformal}: Набір даних олімпіадних математичних задач у формальному вигляді, призначених для забезпечення уніфікованого міжсистемного критерію нейромережевого доведення теорем.
    
    \item {FIMO} \cite{liu2023fimochallengeformaldataset}: Набір формальних даних для автоматизованого доведення теорем, який містить задачі високого рівня складності з анотаціями та формальними доказами.

\end{itemize}

\subsection{Сучасні набори даних}

Цей розділ описує набори даних, які було оприлюднено у 2024 році та розроблено для оцінки можливостей математичного міркування великих мовних моделей. GSM-Symbolic є покращеним бенчмарком, який використовує символьні шаблони для створення контрольованих тестів математичного міркування. OlympiadBench включає задачі олімпіадного рівня з математики та фізики з експертними анотаціями для детального аналізу моделей. OmniMath пропонує складні задачі конкурсного рівня, охоплюючи кілька підрозділів для комплексного оцінювання. CHAMP анотований концептами та підказками, що дозволяє досліджувати вплив додаткової інформації на здатність моделей вирішувати завдання. Physics Language Models концентрується на аналізі процесів міркування моделей та їхньої здатності знаходити математичні рішення, схожі на людські.

\begin{itemize}

    \item {GSM-Symbolic} \cite{mirzadeh2024gsmsymbolicunderstandinglimitationsmathematical}: Покращений бенчмарк, створений на основі символьних шаблонів, що дозволяють генерувати різноманітні набори питань для більш контрольованої оцінки математичних здібностей моделей. Дослідження виявляють суттєву зміну продуктивності моделей при зміні числових значень питань та збільшенні кількості умов у питанні.

    \item {OlympiadBench} \cite{he2024olympiadbenchchallengingbenchmarkpromoting}: Олімпіадний двомовний мультимодальний науковий бенчмарк, що містить 8,476 задач з олімпіадних змагань з математики та фізики, включаючи китайський вступний іспит. Завдання супроводжуються експертними анотаціями для покрокового міркування. Бенчмарк покликаний стати цінним ресурсом для майбутніх досліджень в області штучного загального інтелекту (AGI).

    \item {OmniMath} \cite{gao2024omnimathuniversalolympiadlevel}: Комплексний та складний бенчмарк, спеціально розроблений для оцінки математичних міркувань ВММ на рівні олімпіад. Містить велику колекцію з 4,428 задач конкурсного рівня з ретельними людськими анотаціями, категоризованих у понад 33 математичних підрозділи та 10 рівнів складності.

    \item {CHAMP} \cite{mao2024champcompetitionleveldatasetfinegrained}: Набір даних з проблемами з математичних змагань, анотований концептами та підказками, що дозволяє аналізувати вплив додаткової інформації, такої як відповідні підказки або оманливі концепти. Допомагає досліджувати, чи здатні моделі використовувати сторонню інформацію для покращення результатів розв'язання.

    \item {Physics Language Models} \cite{ye2024physicslanguagemodels21}: Набір даних, що досліджує здатність моделей ВММ вирішувати завдання з математичного міркування. Включає в себе серію контрольованих експериментів для вивчення мисленнєвих процесів моделей, їх здатності розвивати навички міркування, і того, якою мірою моделі можуть вирішувати задачі, що вимагають таких навичок, як у людей.

    \item {NuminaMath} \cite{numina_math_7b}: Набір даних NuminaMath-CoT складається з приблизно 859,608 математичних задач з розв'язаннями у вигляді ланцюжка міркувань (Chain-of-Thought). Дані зібрані з різних освітніх джерел та перекладені англійською мовою. Задачі, що мають короткий числовий розв'язок, були зібрані у окремому наборі даних NuminaMath-TIR, що складається з приблизно 72,540 задач.

\end{itemize}

Існують також версії наборів даних, які не знаходяться у вільному доступі, як наприклад {HiddenMath}, який використовується компанією Google для перевірки математичних можливостей серії моделей Gemini.

\section{Недоліки існуючих наборів даних при роботі з мовними моделями}

Більшість досліджень щодо оцінки мовних моделей у математичному мисленні зазвичай фокусуються на математичних текстових задачах. Набори даних для цієї задачі зазвичай структуровані як математичні твердження та запити, пов'язані з математичними концепціями. Серед найбільш широко використовуваних наборів даних є GSM8K \cite{cobbe2021trainingverifierssolvemath}, SVAMP \cite{patel2021nlpmodelsreallyable}, які фокусуються на арифметичних задачах, MMLU \cite{hendrycks2021measuringmassivemultitasklanguage} -- завдання з множинним вибором відповідей, та MATH \cite{hendrycks2021measuringmathematicalproblemsolving} -- розв'язання текстових задач. Деякі набори даних також включають приклади комбінаторних задач. Однак поява великих мовних моделей висвітлила кілька проблем:

\begin{itemize}
    \item {Дисбаланс рівнів складності} -- Більшість існуючих наборів даних не мають збалансованого рівня складності, маючи або прості арифметичні задачі, або складні завдання олімпіадного рівня. Це обмежує можливість моделей ефективно вирішувати задачі різної складності.
    \item {Забруднення даних} (Data contamination) -- Деякі набори даних містять тестові дані на етапі тренування, що призводить до запам'ятовування моделями шаблонів замість справжнього розуміння та демонстрації здібностей до розв'язання задач.
    \item {Відсутність людської оцінки} -- Мало досліджень надають людську оцінку наборів даних, що є важливим для валідації здатностей моделей до розв'язання проблем.
\end{itemize}

Щоб вирішити ці проблеми, за останні роки було введено кілька нових наборів даних.

\paragraph{Складність задач.} Для підвищення рівня складності зазначені вище набори даних були розширені, а також були представлені нові набори даних зі складними задачами. Наприклад, автори \cite{zheng2022minif2fcrosssystembenchmarkformal} представили miniF2F -- набір даних формальних математичних задач олімпіадного рівня, призначений для забезпечення уніфікованого крос-системного бенчмарку для нейронного доведення теорем. Автори \cite{frieder2023mathematicalcapabilitieschatgpt} створили набір даних GHOSTS для математичних задач випускного рівня. Автори \cite{wang2024mmluprorobustchallengingmultitask} ввели MMLU-Pro -- набір даних, що включає TheoremQA, який містить високоякісні, ручної анотації питання, що потребують застосування теорем для розв'язання, а також SciBench, який містить складні наукові питання, отримані зі студентських екзаменів, забезпечуючи включення питань, узгоджених з навчальним планом. У PuzzleBench \cite{mittal2024puzzlebenchllmssolvechallenging} відібрали обчислювально складні проблеми шляхом ручного перегляду Вікіпедії для різноманітних головоломок та алгоритмічних задач класу NP-тяжких. Крім того, автори експериментували зі зміною конфігурацій певних задач для створення різних рівнів складності завдань.

\paragraph{Забруднення даних.} Автори \cite{golchin2024timetravelllmstracing} використали GSM8K як початковий набір даних і виявили, що у GPT-4 під час використання керованих інструкцій може демонструвати знання наперед відповідних текстів задач, що свідчить про те, що відповідні задачі могли бути присутніми наборах даних для тренування. У роботі \cite{zhang2024carefulexaminationlargelanguage} підкреслили проблему забруднення існуючих наборів даних та за допомогою набору даних GSM8K створили власний набір даних GSK1k, у якому представили нові задачі, які були створені анотаторами вручну. Протестовані моделі показали значно гірші результати на новому наборі задач, що ефективно висвітлює проблему запам'ятовування моделей даних. У сучасних дослідженнях \cite{mirzadeh2024gsmsymbolicunderstandinglimitationsmathematical} автори представили оновлений набір даних GSM-symbolic, створений із систематизованих шаблонів, які дозволяють генерувати різноманітні математичні задачі, та контролювати наступні їхні особливості: заміна персонажів (наприклад, імена), чисел, а також додавання зайвої числової інформації у формулювання задач. Результати показують, що ВММ демонструють значущі погіршення у роботі при генерації розв'язків відповідних варіацій задач.

\paragraph{Людська оцінка.} Автори \cite{collins2023evaluatinglanguagemodelsmathematics} провели перший експеримент з участю людини та ВММ у галузі математики. Автори оцінили корисність ВММ як математичних асистентів через безпосередню взаємодію моделей зі студентами та науковцями та виявили значні відмінності між ефективністю та сприйняттям роботи ВММ. У роботі \cite{zheng2023judgingllmasajudgemtbenchchatbot} автори виявили, що ВММ мають обмеження у проведенні якісного оцінювання наданих розв'язків базових математичних задач, які були попередньо згенеровані тими ж моделями, що підтверджує нерозуміння сутності відповідних задач. Протестована модель GPT-4 змогла розв'язати задачу задану у вигляді окремого запиту, але була введена в оману наданими додатковими запитаннями у продовженні діалогу, що в кінцевому рахунку привело модель до неправильних висновків. У роботі \cite{bubeck2023sparksartificialgeneralintelligence} автори подавали на вхід до мовних моделей математичні твердження, яких раніше не було викладено у вільному доступі. Під час експериментування з моделями, вони демонстрували високий рівень здатності обирати правильний план або послідовність дій до розв'язання задачі, але у багатьох випадках моделям не вдавалося прийти до правильного розв'язку через арифметичні помилки.

Таким чином, існуючі набори даних мають кілька суттєвих недоліків, таких як занадто високий або низький рівень складності задач, використання даних, що були використані у тренуванні моделей, та відсутність людської оцінки, що обмежує їх ефективність у проведенні точної оцінки математичних можливостей мовних моделей. Нові набори даних, що були представлені в останні роки, враховують частину цих обмежень, та пропонують більш збалансовані, контрольовані та перевірені набори даних для подальших досліджень у цій області.

\section{Підготовка нового набору даних}

Для початкового експерименту було розроблено набір даних комбінаторних задач Combi-Puzzles. Набір містить 125 задач у 5 різних варіаціях, що дозволяє тестувати моделі на здатність розв'язувати задачі з числовими, інформаційними та лінгвістичними модифікаціями текстів задач \cite{nikolaiev2024can}.

Було створено набір даних Combi-Puzzles, що містить 125 варіантів задач на основі 25 комбінаторних задач, покриваючи перестановки (з повторенням та без), комбінації, правила додавання та множення, а також розміщення об'єктів з різними обмеженнями. Ці задачі представляють основні принципи комбінаторики, відповідні до навчальної програми середньої школи, і охоплюють рівень складності від простого до середнього.

Було створено п'ять варіацій кожної задачі в контрольований спосіб за допомогою ручних текстових змін поширеної варіації набору задач. Як конкретний приклад, Таблиця~\ref{table:problem_forms} показує задачу номер 10 у всіх її варіаціях з набору даних Combi-Puzzles.

\begin{figure}[ht] \centering \small
    \captionof{table}{Приклад задачі 10 представлений у п'яти варіаціях з набору даних \emph{Combi-Puzzles}. Виділений текст вказує на зміни у порівнянні з початковою формою задачі.}
    \label{table:problem_forms}
    \begin{tabular}{|p{0.2\linewidth}|p{0.75\linewidth}|}
        \hline
        \textbf{Форма задачі} & \textbf{Приклад задачі} \\
        \hline
        Звичайна & 3 дівчини знайшли 9 білих перлин. Скількома різними способами можна розділити всі перлини між дівчатами? Не обов'язково, щоб усі дівчата отримали перлини. \\
        \hline
        Математична & У скрині є 3 кулі, які пронумеровані від 1 до 3. Ви дістаєте кулі 9 разів одну за одною, кожного разу повертаючи кулю назад до скрині. Скільки різних можливих наборів куль ви можете отримати? \\
        \hline
        Надлишкова & 3 дівчини знайшли 9 білих перлин. \hlred{Усі дівчата є професійними фрідайверами і можуть затримувати дихання від 8 до 10 хвилин.} Скількома різними способами можна розділити всі перлини між дівчатами? Не обов'язково, щоб усі дівчата отримали перлини. \\
        \hline
        Параметризована & \hlgreen{13 дівчат} знайшли \hlgreen{54 білих перлини}. Скількома різними способами можна розділити всі перлини між дівчатами? Не обов'язково, щоб усі дівчата отримали перлини. \\
        \hline
        Лінгвістичне заплутування & 3 пірати заходять на фрегат, який щойно здався їм. Вони знають, що на борту є дев'ять злитків золота. По закону піратів будь-який пірат, який знаходить здобич на борту корабля, може її присвоїти. Вони побігли обшукувати кожен кут корабля, щоб знайти золото. Кожен з піратів сподівається відшукати всі дев'ять злитків та хвилюється залишитися без жодного. Скільки існує способів розділити золоті злитки між піратами? \\
        \hline
    \end{tabular}
\end{figure}

\emph{Звичайна варіація (Common)} є поширеною в підручниках з комбінаторики, збірниках математичних змагань та онлайн-ресурсах, таких як веб-сайт AOPS\footnote{\url{https://artofproblemsolving.com/wiki}.}. Дана варіація є загальноприйнятою задля пояснення матеріалу на комбінаторну тематику, основних принципів, а також прикладів задач для учнів у лаштунках шкільної програми.

\emph{Математична варіація (Mathematical)} представлена у природній мові математики, яка зазвичай зустрічається в академічній літературі. Твердження, виражені в цій формі, включають математичні технічні терміни й поняття (наприклад, ``множини'', ``перестановки'', ``модель урни'') та вживані комбінаторні формулювання (наприклад, ``витягування з/без заміщення'').

\emph{Надлишкова варіація (Adversarial)} створена шляхом введення тексту, який додає інформацію, таку як числові дані, до звичайної форми постановки задачі, яка не є релевантною для її розв'язання. Зазвичай вводиться до одного речення, щоб перевірити здатність розв'язувача ідентифікувати релевантну інформацію.

\emph{Параметризована варіація (Parametrisation)} змінює конфігурацію звичайної задачі, зазвичай збільшуючи значення параметрів для розширення простору можливих варіантів, які задовольняють умові задачі, тим самим ускладняючи її рівень.

\emph{Лінгвістичне заплутування (Lingustic obfuscation)} створюється шляхом зміни наративного стилю постановки задачі та перетворення її на розповідь вигаданої історії. Ця варіація може включати додаткові описи, нерелевантні числові дані та нові імена. Кожен екземпляр цієї варіації має довжину від 300 символів тексту. Цей підхід перевіряє здатність розв'язувачів витягувати основну суть задачі.

Математична, надлишкова, параметризація та лінгвістичне заплутування є новими варіаціями задач, створеними спеціально для цього дослідження. Ці варіації моделюють різноманітні способи формулювання задачі, дозволяючи оцінити здатність як людей, так і ВММ визначати правильну стратегію розв'язання для кожної задачі.

Усі варіації були створені систематично, дотримуючись наведених вище керівних принципів, таким чином, щоб зберегти основний математичний зміст та інформацію, необхідну для розв'язання задачі. Текстові зміни, що використовує лінгвістичне заплутування для оцінки ефективності великих мовних моделей, є новим у роботі текстовою маніпуляцією даних.

Знайти повний набір задач можна у репозиторії на сервісі Hugging Face\footnote{\url{https://huggingface.co/datasets/andynik/combi-puzzles}.}.

\section{Відбір даних}
\label{sec:problem-selection}

Процес відбору даних складається з двох головних етапів: (i) фільтрація комбінаторних задач за допомогою ключових слів; та (ii) числова обробка текстів за допомогою ВММ та вилучення розв'язків на основі регулярних виразів. Задля вищої точності роботи з моделями, а також оскільки вхідні дані задані англійською мовою, усі інструкції передавалися до моделей англійською мовою.

\begin{figure}[ht]
    \centering
    \captionof{table}{Опис джерел набору даних на етапах роботи з даними.}
    \label{tab:merged_sources}
    \begin{tabular}{|l|r|r|}
        \hline
        Джерело / Вибірка & Вхідна & Відфільтр. \\
        \hline
        aops\_forum & 30,201 & 96 \\
        amc\_aime & 4,072 & 25 \\
        cn\_k12 & 276,591 & 420 \\
        gsm8k & 7,345 & 7 \\
        math & 7,478 & 77 \\
        olympiads & 150,581 & 880 \\
        orca\_math & 153,334 & 627 \\
        synthetic\_amc & 62,111 & 280 \\
        synthetic\_math & 167,895 & 3,171 \\
        \hline
        \textbf{Разом} & \textbf{859,608} & \textbf{5,583} \\
        \hline
    \end{tabular}
\end{figure}

\subsection{Опис вхідного набору даних}
Набір даних NuminaMath-CoT є основним джерелом для проведення дослідження та містить 859,608 математичних задач, отриманих з різних освітніх джерел та перекладаних англійською. Кожна задача з набору даних містить наступні поля: \texttt{source}, \texttt{problem}, \texttt{solution}, \texttt{messages}. Для даного дослідження було обрано задачі з комбінаторного розділу, які містять кінцевий числовий розв'язок.

\subsection{Відбір комбінаторних задач}

\textbf{Початкова фільтрація:} Процес фільтрації розпочався з виявлення задач, що містять фразу ``hom much'' в умові задачі (стовпчик \texttt{problem}). Ця фраза була обрана через її поширене вживання в комбінаторних задачах, які зазвичай передбачають підрахунок кількості можливих конфігурацій або результатів. Однак ця початкова фільтрація дала приблизно 250,000 задач, що охоплюють задачі на різноманітні математичні розділи, зокрема такими, що не пов'язані з комбінаторними задачами, як наприклад, геометричні задачі на тему планіметрії.

\textbf{Ідентифікація комбінаторних задач:} Щоб ще більше зменшити область пошуку, було проаналізували стовпчик \texttt{solution} на предмет наявності комбінаторної термінології. Для виявлення задач з комбінаторним акцентом було використано набір ключових слів, таких як ``permutation'', ``combination'', ``arrangement'' та інші. Цей процес фільтрації скоротив наш набір даних до приблизно 100 000 задач, але які все ще включають задачі з інших математичних тем.

\textbf{Виключення нерелевантних математичних задач:} Щоб зосередитися на комбінаторних задачах, з відібраного набору даних було виключено задачі на тему алгебри, теорії чисел і геометрії за допомогою таких ключових слів, як ``equation'', ``variable'', ``polynom'', ``angle'', ``perimeter'', ``prism'' тощо у стовпчиках з умовою задачі або розв'язанням (стовпчики \texttt{problem} та \texttt{solution} відповідно). Завдяки цьому кілько-кроковому процесу фільтрації даних було успішно зменшено набір даних до приблизно 10,000 задач, які відповідають завданим критеріям.

Таким чином, шляхом ретельної стратегії фільтрації даних за ключовими словами було успішно ізольовано набір комбінаторних задач. Цей процес підтримує подальший аналіз у запропонованому дослідженні, забезпечуючи при цьому мінімальне втручання інших математичних розділів. Проте багато задач не мають єдиного числового розв'язку. З цієї причини було виконано додатковий етап фільтрації.

\subsection{Вилучення числових розв'язків}

У цьому розділі детально описано нейромережевий метод, який використовується для вилучення числових розв'язків з набору даних. Процес вилучення розв'язків вбудований у дану систему та використовує регулярні вирази і мовну модель для виконання завдання. Вилучення числових розв'язків з наборів даних комбінаторних задач є важливим компонентом даного дослідження. 

\subsubsection{Етап 1: Вилучення відповіді за допомогою мовної моделі}

На цьому етапі було оцінено кілька відкритих мовних моделей розміром до 8 млрд. параметрів за критеріями точності та швидкості обробки запитів. Модель Mathstral-7B продемонструвала найкращі результати порівняно з версіями моделей Qwen 2 та LLaMA (2 і 3) аналогічного розміру.  

Mathstral-7B\footnote{\url{https://mistral.ai/news/mathstral/}} -- це модель, яка спеціалізується на математичних і наукових задачах та створена на базі ВММ Mistral-7B. Вона була обрана завдяки високій точності та швидкій обробці математичних даних, що робить її ефективною для роботи з великими обсягами інформації.

Оцінювання проводилося шляхом порівняння результатів моделей з відомими наборами розв'язків для вибірки задач. Ключовим показником є оцінки точності роботи моделі, яка вимірює відсоток правильно отриманих числових розв'язків.

\textbf{Побудова запиту:} Для вилучення числового розв'язку з наведеного розв'язання задачі утворюється спеціальний запит. Запит формується з чіткою інструкцією до моделі вказати остаточний числовий розв'язок або повернути символ мінус ``-'' у випадку, якщо даний запит неможливо виконати успішно. Це вбудовано у наступний структурований запит:

\begin{lstlisting}[language=json, breaklines=true]
{"content": "Please identify and extract the single numerical 
            value that represents the final answer from the
            following text below. If there is no single 
            numerical answer, respond with `-'. Problem    
            solution: {problem_solution}"}
\end{lstlisting}

Вхідний набір даних доповнено додатковим стовпчиком \texttt{answer}, який представляє числовий розв'язок для кожної задачі, вилученої з даних стовпчика \texttt{solution}.

Цей метод дозволяє ефективно отримувати числові відповіді для серії комбінаторних задач, з надійною обробкою помилок для управління будь-якими винятками, які можуть виникнути під час процесу. Така автоматизація полегшує масштабування та спрощує обробку даних.

\subsubsection{Етап 2: Вилучення відповіді на основі регулярних виразів}

Наступний етап запропонованого методу використовує функцію, яка застосовує регулярний вираз для ідентифікації та вилучення значень зі стовпчика набору даних \texttt{answer}, за допомогою якого з тексту розв'язків повернутих моделлю вилучаються лише додатні та від'ємні цілі числа. Задачі з кількома, нецілими або нечисловими відповідями було прибрано з відфільтрованого набору даних. У деяких випадках, коли мовна модель не може ідентифікувати єдиний числовий розв'язок, було використано додаткові умови фільтрації. 

Кожна задача обробляється для оцінки її числового значення. Цей процес зменшив оброблений відфільтрований набір даних до 5,583 задач з відфільтрованого набору даних для виконання решти дослідження. Оброблений набір даних експортуються у форматах Parquet і JSON, що дозволяє безперешкодно інтегрувати його з іншими частинами аналізу даних. У таблиці~\ref{tab:merged_sources} представлено результати процесу фільтрації набору даних за джерелами.


\section{Підсумки розділу}
Було проведено детальний аналіз різних методів підготовки та синтезу математичних комбінаторних задач із застосуванням великих мовних моделей. У розділі докладно було описано як традиційну анотацію за участі експертів, так і генерацію синтетичних даних за допомогою ВММ, що дозволило не лише збільшити обсяг навчального корпусу, але й забезпечити різноманітність формулювань задач. Було проведено огляд як класичних наборів даних, таких як GSM8K, MATH, MMLU, MiniF2F та FIMO, так і сучасних методів оцінювання, що враховують змінність рівнів складності та особливості математичних задач, що дає можливість більш точно тестувати можливості мовних моделей.

Було ретельно проведено аналіз недоліків існуючих наборів даних, серед яких нерівномірність рівнів складності, проблема контамінації даних під час навчання моделей та обмеженість людської оцінки. Для вирішення зазначених проблем було розроблено унікальний набір даних \emph{Combi-Puzzles}, який складається з 125 комбінаторних задач, що представлені у п’яти варіаціях. Така методологія дозволяє оцінити здатність моделей ідентифікувати релевантну інформацію незалежно від стилістичних змін у формулюванні задачі або введення додаткових, нерелевантних елементів.

Було також проведено детальний опис етапів відбору даних для подальшої генерації текстів. Процес починався з початкової фільтрації за ключовими словами, який дозволив скоротити початковий набір задач у кілька разів. Після цього відбувався подальший етап відбору на основі аналізу текстів за наявністю відповідної до математичних розділів термінології у розв'язаннях та використання регулярних виразів для вилучення числових розв'язків. Це забезпечило відбір підмножини математичних комбінаторних задач з 5,583 прикладів. Важливим аспектом був вибір ефективної моделі, зокрема Mathstral-7B, для автоматичного вилучення числових розв'язків, що дозволило підвищити швидкість та точність обробки даних.

Таким чином, розділ не лише узагальнює методологічні методи до синтезу та відбору математичних комбінаторних задач, але й демонструє практичну реалізацію розробленої схеми збору даних, що формує надійну основу для подальшого експериментування з можливостями ВММ у галузі математичного міркування.

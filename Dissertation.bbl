\begin{thebibliography}{91}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Glushkov(1970)]{glushkov1970some}
V.~M. Glushkov.
\newblock Some problems in the theories of automata and artificial intelligence.
\newblock \emph{Cybernetics}, 6\penalty0 (2):\penalty0 17--27, Mar 1970.
\newblock ISSN 1573-8337.
\newblock \doi{10.1007/BF01070496}.
\newblock URL \url{https://doi.org/10.1007/BF01070496}.

\bibitem[Glushkov et~al.(1970)Glushkov, Kapitonova, and Letichevskii]{Glushkov1970}
V.~M. Glushkov, Yu.~V. Kapitonova, and A.~A. Letichevskii.
\newblock Software for an automatic system of design of computers and systems (proekt).
\newblock \emph{Cybernetics}, 6\penalty0 (4):\penalty0 363--368, Jul 1970.
\newblock ISSN 1573-8337.
\newblock \doi{10.1007/BF01073232}.
\newblock URL \url{https://doi.org/10.1007/BF01073232}.

\bibitem[Glushkov and Kapitonova(1972)]{Glushkov1972}
V.~M. Glushkov and Yu.~V. Kapitonova.
\newblock Automatic search for proofs of mathematical theorems and intelligent computers.
\newblock \emph{Cybernetics}, 8\penalty0 (5):\penalty0 709--713, Sep 1972.
\newblock ISSN 1573-8337.
\newblock \doi{10.1007/BF01068443}.
\newblock URL \url{https://doi.org/10.1007/BF01068443}.

\bibitem[Glushkov(1980)]{glushovsad1980}
Victor~M. Glushkov.
\newblock The sad automated proving system: A brief informal presentation.
\newblock \emph{Automated Processing of Mathematical Texts}, pages 3--30, 1980.

\bibitem[Verchinine et~al.(2007)Verchinine, Lyaletski, and Paskevich]{10.1007/978-3-540-73595-3_29}
Konstantin Verchinine, Alexander Lyaletski, and Andrei Paskevich.
\newblock System for automated deduction (sad): a tool for proof verification.
\newblock In \emph{International Conference on Automated Deduction}, pages 398--403. Springer, 2007.
\newblock \doi{10.1007/978-3-540-73595-3_29}.
\newblock URL \url{https://doi.org/10.1007/978-3-540-73595-3_29}.

\bibitem[Paulson(1986)]{paulson1986natural}
L.~C. Paulson.
\newblock Natural deduction as higher-order resolution.
\newblock \emph{The Journal of Logic Programming}, 3\penalty0 (3):\penalty0 237--258, 1986.
\newblock \doi{10.1016/0743-1066(86)90015-4}.
\newblock URL \url{https://doi.org/10.1016/0743-1066(86)90015-4}.

\bibitem[De~Moura et~al.(2015)De~Moura, Kong, Avigad, Van~Doorn, and Von~Raumer]{demoura2015lean}
Leonardo De~Moura, Soonho Kong, Jeremy Avigad, Floris Van~Doorn, and Jakob Von~Raumer.
\newblock The lean theorem prover (system description).
\newblock In \emph{International Conference on Automated Deduction}, pages 378--388. Springer, 2015.
\newblock \doi{10.1007/978-3-319-21401-6_26}.
\newblock URL \url{https://doi.org/10.1007/978-3-319-21401-6_26}.

\bibitem[Verchinine et~al.(2008)Verchinine, Lyaletski, Paskevich, and Anisimov]{10.1007/978-3-540-85110-3_47}
Konstantin Verchinine, Alexander Lyaletski, Andrey Paskevich, and Anatoly Anisimov.
\newblock On correctness of mathematical texts from a logical and practical point of view.
\newblock In \emph{International Conference on Intelligent Computer Mathematics}, pages 583--598. Springer, 2008.
\newblock \doi{10.1007/978-3-540-85110-3_47}.
\newblock URL \url{https://doi.org/10.1007/978-3-540-85110-3_47}.

\bibitem[Liu et~al.(2023)Liu, Shen, Xin, Liu, Yuan, Wang, Ju, Zheng, Yin, Li, Zhang, and Liu]{liu2023fimochallengeformaldataset}
Chengwu Liu, Jianhao Shen, Huajian Xin, Zhengying Liu, Ye~Yuan, Haiming Wang, Wei Ju, Chuanyang Zheng, Yichun Yin, Lin Li, Ming Zhang, and Qun Liu.
\newblock Fimo: A challenge formal dataset for automated theorem proving, 2023.
\newblock URL \url{https://arxiv.org/abs/2309.04295}.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan, Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess, Clark, Berner, McCandlish, Radford, Sutskever, and Amodei]{brown2020languagemodelsfewshotlearners}
Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.
\newblock Language models are few-shot learners, 2020.
\newblock URL \url{https://arxiv.org/abs/2005.14165}.

\bibitem[Polu and Sutskever(2020)]{polu2020generativelanguagemodelingautomated}
Stanislas Polu and Ilya Sutskever.
\newblock Generative language modeling for automated theorem proving, 2020.
\newblock URL \url{https://arxiv.org/abs/2009.03393}.

\bibitem[Zheng et~al.(2022)Zheng, Han, and Polu]{zheng2022minif2fcrosssystembenchmarkformal}
Kunhao Zheng, Jesse~Michael Han, and Stanislas Polu.
\newblock Minif2f: a cross-system benchmark for formal olympiad-level mathematics, 2022.
\newblock URL \url{https://arxiv.org/abs/2109.00110}.

\bibitem[Han et~al.(2022)Han, Rute, Wu, Ayers, and Polu]{han2022proofartifactcotrainingtheorem}
Jesse~Michael Han, Jason Rute, Yuhuai Wu, Edward~W. Ayers, and Stanislas Polu.
\newblock Proof artifact co-training for theorem proving with language models, 2022.
\newblock URL \url{https://arxiv.org/abs/2102.06203}.

\bibitem[Wang et~al.(2023)Wang, Yuan, Liu, Shen, Yin, Xiong, Xie, Shi, Li, Li, Yin, Li, and Liang]{wang-etal-2023-dt}
Haiming Wang, Ye~Yuan, Zhengying Liu, Jianhao Shen, Yichun Yin, Jing Xiong, Enze Xie, Han Shi, Yujun Li, Lin Li, Jian Yin, Zhenguo Li, and Xiaodan Liang.
\newblock {DT}-solver: Automated theorem proving with dynamic-tree sampling guided by proof-level value function.
\newblock In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki, editors, \emph{Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 12632--12646, Toronto, Canada, July 2023. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.acl-long.706}.
\newblock URL \url{https://aclanthology.org/2023.acl-long.706/}.

\bibitem[Hosseini et~al.(2014)Hosseini, Hajishirzi, Etzioni, and Kushman]{hosseini-etal-2014-learning}
Mohammad~Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman.
\newblock Learning to solve arithmetic word problems with verb categorization.
\newblock In Alessandro Moschitti, Bo~Pang, and Walter Daelemans, editors, \emph{Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})}, pages 523--533, Doha, Qatar, October 2014. Association for Computational Linguistics.
\newblock \doi{10.3115/v1/D14-1058}.
\newblock URL \url{https://aclanthology.org/D14-1058/}.

\bibitem[Mitra and Baral(2016)]{mitra-baral-2016-learning}
Arindam Mitra and Chitta Baral.
\newblock Learning to use formulas to solve simple arithmetic problems.
\newblock In Katrin Erk and Noah~A. Smith, editors, \emph{Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 2144--2153, Berlin, Germany, August 2016. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P16-1202}.
\newblock URL \url{https://aclanthology.org/P16-1202/}.

\bibitem[Koncel-Kedziorski et~al.(2015{\natexlab{a}})Koncel-Kedziorski, Hajishirzi, Sabharwal, Etzioni, and Ang]{koncel-kedziorski-etal-2015-parsing}
Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish Sabharwal, Oren Etzioni, and Siena~Dumas Ang.
\newblock Parsing algebraic word problems into equations.
\newblock \emph{Transactions of the Association for Computational Linguistics}, 3:\penalty0 585--597, 2015{\natexlab{a}}.
\newblock \doi{10.1162/tacl_a_00160}.
\newblock URL \url{https://aclanthology.org/Q15-1042/}.

\bibitem[Roy and Roth(2016)]{roy2016solvinggeneralarithmeticword}
Subhro Roy and Dan Roth.
\newblock Solving general arithmetic word problems, 2016.
\newblock URL \url{https://arxiv.org/abs/1608.01413}.

\bibitem[Wang et~al.(2018{\natexlab{a}})Wang, Zhang, Gao, Song, Guo, and Shen]{Wang_Zhang_Gao_Song_Guo_Shen_2018}
Lei Wang, Dongxiang Zhang, Lianli Gao, Jingkuan Song, Long Guo, and Heng~Tao Shen.
\newblock Mathdqn: Solving arithmetic word problems via deep reinforcement learning.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, 32\penalty0 (1), Apr. 2018{\natexlab{a}}.
\newblock \doi{10.1609/aaai.v32i1.11981}.
\newblock URL \url{https://ojs.aaai.org/index.php/AAAI/article/view/11981}.

\bibitem[Wang et~al.(2018{\natexlab{b}})Wang, Wang, Cai, Zhang, and Liu]{wang2018translatingmathwordproblem}
Lei Wang, Yan Wang, Deng Cai, Dongxiang Zhang, and Xiaojiang Liu.
\newblock Translating a math word problem to an expression tree, 2018{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/1811.05632}.

\bibitem[Vaswani et~al.(2023)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{vaswani2023attentionneed}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need, 2023.
\newblock URL \url{https://arxiv.org/abs/1706.03762}.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{devlin2019bertpretrainingdeepbidirectional}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding, 2019.
\newblock URL \url{https://arxiv.org/abs/1810.04805}.

\bibitem[Yenduri et~al.(2023)Yenduri, M, G, Y, Srivastava, Maddikunta, G, Jhaveri, B, Wang, Vasilakos, and Gadekallu]{yenduri2023generativepretrainedtransformercomprehensive}
Gokul Yenduri, Ramalingam M, Chemmalar~Selvi G, Supriya Y, Gautam Srivastava, Praveen Kumar~Reddy Maddikunta, Deepti~Raj G, Rutvij~H Jhaveri, Prabadevi B, Weizheng Wang, Athanasios~V. Vasilakos, and Thippa~Reddy Gadekallu.
\newblock Generative pre-trained transformer: A comprehensive review on enabling technologies, potential applications, emerging challenges, and future directions, 2023.
\newblock URL \url{https://arxiv.org/abs/2305.10435}.

\bibitem[Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin, Zhang, Agarwal, Slama, Ray, Schulman, Hilton, Kelton, Miller, Simens, Askell, Welinder, Christiano, Leike, and Lowe]{ouyang2022traininglanguagemodelsfollow}
Long Ouyang, Jeff Wu, Xu~Jiang, Diogo Almeida, Carroll~L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe.
\newblock Training language models to follow instructions with human feedback, 2022.
\newblock URL \url{https://arxiv.org/abs/2203.02155}.

\bibitem[team(2024)]{openai2024gpt4technicalreport}
OpenAI team.
\newblock Gpt-4 technical report, 2024.
\newblock URL \url{https://arxiv.org/abs/2303.08774}.

\bibitem[Jacobs et~al.(1991)Jacobs, Jordan, Nowlan, and Hinton]{6797059}
Robert~A. Jacobs, Michael~I. Jordan, Steven~J. Nowlan, and Geoffrey~E. Hinton.
\newblock Adaptive mixtures of local experts.
\newblock \emph{Neural Computation}, 3\penalty0 (1):\penalty0 79--87, 1991.
\newblock \doi{10.1162/neco.1991.3.1.79}.

\bibitem[Eigen et~al.(2014)Eigen, Ranzato, and Sutskever]{eigen2014learningfactoredrepresentationsdeep}
David Eigen, Marc'Aurelio Ranzato, and Ilya Sutskever.
\newblock Learning factored representations in a deep mixture of experts, 2014.
\newblock URL \url{https://arxiv.org/abs/1312.4314}.

\bibitem[Bengio et~al.(2016)Bengio, Bacon, Pineau, and Precup]{bengio2016conditionalcomputationneuralnetworks}
Emmanuel Bengio, Pierre-Luc Bacon, Joelle Pineau, and Doina Precup.
\newblock Conditional computation in neural networks for faster models, 2016.
\newblock URL \url{https://arxiv.org/abs/1511.06297}.

\bibitem[Shazeer et~al.(2017)Shazeer, Mirhoseini, Maziarz, Davis, Le, Hinton, and Dean]{shazeer2017outrageouslylargeneuralnetworks}
Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean.
\newblock Outrageously large neural networks: The sparsely-gated mixture-of-experts layer, 2017.
\newblock URL \url{https://arxiv.org/abs/1701.06538}.

\bibitem[Fedus et~al.(2022)Fedus, Zoph, and Shazeer]{fedus2022switchtransformersscalingtrillion}
William Fedus, Barret Zoph, and Noam Shazeer.
\newblock Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity, 2022.
\newblock URL \url{https://arxiv.org/abs/2101.03961}.

\bibitem[Lepikhin et~al.(2020)Lepikhin, Lee, Xu, Chen, Firat, Huang, Krikun, Shazeer, and Chen]{lepikhin2020gshardscalinggiantmodels}
Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and Zhifeng Chen.
\newblock Gshard: Scaling giant models with conditional computation and automatic sharding, 2020.
\newblock URL \url{https://arxiv.org/abs/2006.16668}.

\bibitem[Xue et~al.(2024)Xue, Zheng, Fu, Ni, Zheng, Zhou, and You]{xue2024openmoeearlyeffortopen}
Fuzhao Xue, Zian Zheng, Yao Fu, Jinjie Ni, Zangwei Zheng, Wangchunshu Zhou, and Yang You.
\newblock Openmoe: An early effort on open mixture-of-experts language models, 2024.
\newblock URL \url{https://arxiv.org/abs/2402.01739}.

\bibitem[Jiang et~al.(2024)Jiang, Sablayrolles, Roux, Mensch, Savary, Bamford, Chaplot, de~las Casas, Hanna, Bressand, Lengyel, Bour, Lample, Lavaud, Saulnier, Lachaux, Stock, Subramanian, Yang, Antoniak, Scao, Gervet, Lavril, Wang, Lacroix, and Sayed]{jiang2024mixtralexperts}
Albert~Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra~Singh Chaplot, Diego de~las Casas, Emma~Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, Lélio~Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven~Le Scao, Théophile Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William~El Sayed.
\newblock Mixtral of experts, 2024.
\newblock URL \url{https://arxiv.org/abs/2401.04088}.

\bibitem[Jiang et~al.(2023)Jiang, Sablayrolles, Mensch, Bamford, Chaplot, de~las Casas, Bressand, Lengyel, Lample, Saulnier, Lavaud, Lachaux, Stock, Scao, Lavril, Wang, Lacroix, and Sayed]{jiang2023mistral7b}
Albert~Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra~Singh Chaplot, Diego de~las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio~Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven~Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William~El Sayed.
\newblock Mistral 7b, 2023.
\newblock URL \url{https://arxiv.org/abs/2310.06825}.

\bibitem[Team(2023)]{touvron2023llama2openfoundation}
Llama~2 Team.
\newblock Llama 2: Open foundation and fine-tuned chat models, 2023.
\newblock URL \url{https://arxiv.org/abs/2307.09288}.

\bibitem[Kojima et~al.(2023)Kojima, Gu, Reid, Matsuo, and Iwasawa]{kojima2023largelanguagemodelszeroshot}
Takeshi Kojima, Shixiang~Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa.
\newblock Large language models are zero-shot reasoners, 2023.
\newblock URL \url{https://arxiv.org/abs/2205.11916}.

\bibitem[Wei et~al.(2023)Wei, Wang, Schuurmans, Bosma, Ichter, Xia, Chi, Le, and Zhou]{wei2023chainofthoughtpromptingelicitsreasoning}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed~Chi, Quoc Le, and Denny Zhou.
\newblock Chain-of-thought prompting elicits reasoning in large language models, 2023.
\newblock URL \url{https://arxiv.org/abs/2201.11903}.

\bibitem[Zhang et~al.(2022)Zhang, Zhang, Li, and Smola]{zhang2022automaticchainthoughtprompting}
Zhuosheng Zhang, Aston Zhang, Mu~Li, and Alex Smola.
\newblock Automatic chain of thought prompting in large language models, 2022.
\newblock URL \url{https://arxiv.org/abs/2210.03493}.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and Klimov]{schulman2017proximalpolicyoptimizationalgorithms}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms, 2017.
\newblock URL \url{https://arxiv.org/abs/1707.06347}.

\bibitem[Ziegler et~al.(2020)Ziegler, Stiennon, Wu, Brown, Radford, Amodei, Christiano, and Irving]{ziegler2020finetuninglanguagemodelshuman}
Daniel~M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom~B. Brown, Alec Radford, Dario Amodei, Paul Christiano, and Geoffrey Irving.
\newblock Fine-tuning language models from human preferences, 2020.
\newblock URL \url{https://arxiv.org/abs/1909.08593}.

\bibitem[Rafailov et~al.(2024)Rafailov, Sharma, Mitchell, Ermon, Manning, and Finn]{rafailov2024directpreferenceoptimizationlanguage}
Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher~D. Manning, and Chelsea Finn.
\newblock Direct preference optimization: Your language model is secretly a reward model, 2024.
\newblock URL \url{https://arxiv.org/abs/2305.18290}.

\bibitem[Lee et~al.(2024)Lee, Phatale, Mansoor, Mesnard, Ferret, Lu, Bishop, Hall, Carbune, Rastogi, and Prakash]{lee2024rlaifvsrlhfscaling}
Harrison Lee, Samrat Phatale, Hassan Mansoor, Thomas Mesnard, Johan Ferret, Kellie Lu, Colton Bishop, Ethan Hall, Victor Carbune, Abhinav Rastogi, and Sushant Prakash.
\newblock Rlaif vs. rlhf: Scaling reinforcement learning from human feedback with ai feedback, 2024.
\newblock URL \url{https://arxiv.org/abs/2309.00267}.

\bibitem[Hejna et~al.(2024)Hejna, Rafailov, Sikchi, Finn, Niekum, Knox, and Sadigh]{hejna2024contrastivepreferencelearninglearning}
Joey Hejna, Rafael Rafailov, Harshit Sikchi, Chelsea Finn, Scott Niekum, W.~Bradley Knox, and Dorsa Sadigh.
\newblock Contrastive preference learning: Learning from human feedback without rl, 2024.
\newblock URL \url{https://arxiv.org/abs/2310.13639}.

\bibitem[Gulcehre et~al.(2023)Gulcehre, Paine, Srinivasan, Konyushkova, Weerts, Sharma, Siddhant, Ahern, Wang, Gu, Macherey, Doucet, Firat, and de~Freitas]{gulcehre2023reinforcedselftrainingrestlanguage}
Caglar Gulcehre, Tom~Le Paine, Srivatsan Srinivasan, Ksenia Konyushkova, Lotte Weerts, Abhishek Sharma, Aditya Siddhant, Alex Ahern, Miaosen Wang, Chenjie Gu, Wolfgang Macherey, Arnaud Doucet, Orhan Firat, and Nando de~Freitas.
\newblock Reinforced self-training (rest) for language modeling, 2023.
\newblock URL \url{https://arxiv.org/abs/2308.08998}.

\bibitem[Zhang et~al.(2023)Zhang, Liu, Wong, Abbeel, and Gonzalez]{zhang2023wisdomhindsightmakeslanguage}
Tianjun Zhang, Fangchen Liu, Justin Wong, Pieter Abbeel, and Joseph~E. Gonzalez.
\newblock The wisdom of hindsight makes language models better instruction followers, 2023.
\newblock URL \url{https://arxiv.org/abs/2302.05206}.

\bibitem[Bai et~al.(2022)Bai, Kadavath, Kundu, Askell, Kernion, Jones, Chen, Goldie, Mirhoseini, McKinnon, Chen, Olsson, Olah, Hernandez, Drain, Ganguli, Li, Tran-Johnson, Perez, Kerr, Mueller, Ladish, Landau, Ndousse, Lukosuite, Lovitt, Sellitto, Elhage, Schiefer, Mercado, DasSarma, Lasenby, Larson, Ringer, Johnston, Kravec, Showk, Fort, Lanham, Telleen-Lawton, Conerly, Henighan, Hume, Bowman, Hatfield-Dodds, Mann, Amodei, Joseph, McCandlish, Brown, and Kaplan]{bai2022constitutionalaiharmlessnessai}
Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, Carol Chen, Catherine Olsson, Christopher Olah, Danny Hernandez, Dawn Drain, Deep Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perez, Jamie Kerr, Jared Mueller, Jeffrey Ladish, Joshua Landau, Kamal Ndousse, Kamile Lukosuite, Liane Lovitt, Michael Sellitto, Nelson Elhage, Nicholas Schiefer, Noemi Mercado, Nova DasSarma, Robert Lasenby, Robin Larson, Sam Ringer, Scott Johnston, Shauna Kravec, Sheer~El Showk, Stanislav Fort, Tamera Lanham, Timothy Telleen-Lawton, Tom Conerly, Tom Henighan, Tristan Hume, Samuel~R. Bowman, Zac Hatfield-Dodds, Ben Mann, Dario Amodei, Nicholas Joseph, Sam McCandlish, Tom Brown, and Jared Kaplan.
\newblock Constitutional ai: Harmlessness from ai feedback, 2022.
\newblock URL \url{https://arxiv.org/abs/2212.08073}.

\bibitem[Levonian et~al.(2023)Levonian, Li, Zhu, Gade, Henkel, Postle, and Xing]{levonian2023retrievalaugmentedgenerationimprovemath}
Zachary Levonian, Chenglu Li, Wangda Zhu, Anoushka Gade, Owen Henkel, Millie-Ellen Postle, and Wanli Xing.
\newblock Retrieval-augmented generation to improve math question-answering: Trade-offs between groundedness and human preference, 2023.
\newblock URL \url{https://arxiv.org/abs/2310.03184}.

\bibitem[Zelikman et~al.(2022)Zelikman, Wu, Mu, and Goodman]{zelikman2022starbootstrappingreasoningreasoning}
Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah~D. Goodman.
\newblock Star: Bootstrapping reasoning with reasoning, 2022.
\newblock URL \url{https://arxiv.org/abs/2203.14465}.

\bibitem[Zelikman et~al.(2024)Zelikman, Harik, Shao, Jayasiri, Haber, and Goodman]{zelikman2024quietstarlanguagemodelsteach}
Eric Zelikman, Georges Harik, Yijia Shao, Varuna Jayasiri, Nick Haber, and Noah~D. Goodman.
\newblock Quiet-star: Language models can teach themselves to think before speaking, 2024.
\newblock URL \url{https://arxiv.org/abs/2403.09629}.

\bibitem[Team(2025{\natexlab{a}})]{deepseekai2025deepseekr1incentivizingreasoningcapability}
DeepSeek-AI Team.
\newblock Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning, 2025{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2501.12948}.

\bibitem[Team(2025{\natexlab{b}})]{kimiteam2025kimik15scalingreinforcement}
Kimi Team.
\newblock Kimi k1.5: Scaling reinforcement learning with llms, 2025{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2501.12599}.

\bibitem[Bubeck et~al.(2023)Bubeck, Chandrasekaran, Eldan, Gehrke, Horvitz, Kamar, Lee, Lee, Li, Lundberg, Nori, Palangi, Ribeiro, and Zhang]{bubeck2023sparksartificialgeneralintelligence}
Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin~Tat Lee, Yuanzhi Li, Scott Lundberg, Harsha Nori, Hamid Palangi, Marco~Tulio Ribeiro, and Yi~Zhang.
\newblock Sparks of artificial general intelligence: Early experiments with gpt-4, 2023.
\newblock URL \url{https://arxiv.org/abs/2303.12712}.

\bibitem[Gao et~al.(2023)Gao, Madaan, Zhou, Alon, Liu, Yang, Callan, and Neubig]{gao2023palprogramaidedlanguagemodels}
Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig.
\newblock Pal: Program-aided language models, 2023.
\newblock URL \url{https://arxiv.org/abs/2211.10435}.

\bibitem[Gou et~al.(2024)Gou, Shao, Gong, Shen, Yang, Huang, Duan, and Chen]{gou2024toratoolintegratedreasoningagent}
Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Minlie Huang, Nan Duan, and Weizhu Chen.
\newblock Tora: A tool-integrated reasoning agent for mathematical problem solving, 2024.
\newblock URL \url{https://arxiv.org/abs/2309.17452}.

\bibitem[Ніколаєв(2024)]{nikolaiev2024neuralform}
Андрій Ніколаєв.
\newblock Нейромережеві методи формалізації математичних текстів.
\newblock \emph{Herald of Khmelnytskyi National University. Technical sciences}, 345\penalty0 (6(2)):\penalty0 50–55, Nov. 2024.
\newblock \doi{10.31891/2307-5732-2024-345-6-6}.
\newblock URL \url{https://doi.org/10.31891/2307-5732-2024-345-6-6}.

\bibitem[Trinh et~al.(2024)Trinh, Wu, Le, He, and Luong]{Trinh2024SolvingOG}
Trieu~H. Trinh, Yuhuai Wu, Quoc~V. Le, He~He, and Thang Luong.
\newblock Solving olympiad geometry without human demonstrations.
\newblock \emph{Nature}, 625:\penalty0 476 -- 482, 2024.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:267032902}.

\bibitem[Frieder et~al.(2023)Frieder, Pinchetti, Chevalier, Griffiths, Salvatori, Lukasiewicz, Petersen, and Berner]{frieder2023mathematicalcapabilitieschatgpt}
Simon Frieder, Luca Pinchetti, Alexis Chevalier, Ryan-Rhys Griffiths, Tommaso Salvatori, Thomas Lukasiewicz, Philipp~Christian Petersen, and Julius Berner.
\newblock Mathematical capabilities of chatgpt, 2023.
\newblock URL \url{https://arxiv.org/abs/2301.13867}.

\bibitem[Cobbe et~al.(2021)Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser, Plappert, Tworek, Hilton, Nakano, Hesse, and Schulman]{cobbe2021trainingverifierssolvemath}
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman.
\newblock Training verifiers to solve math word problems, 2021.
\newblock URL \url{https://arxiv.org/abs/2110.14168}.

\bibitem[Hendrycks et~al.(2021{\natexlab{a}})Hendrycks, Burns, Kadavath, Arora, Basart, Tang, Song, and Steinhardt]{hendrycks2021measuringmathematicalproblemsolving}
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt.
\newblock Measuring mathematical problem solving with the math dataset, 2021{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2103.03874}.

\bibitem[Collins et~al.(2023)Collins, Jiang, Frieder, Wong, Zilka, Bhatt, Lukasiewicz, Wu, Tenenbaum, Hart, Gowers, Li, Weller, and Jamnik]{collins2023evaluatinglanguagemodelsmathematics}
Katherine~M. Collins, Albert~Q. Jiang, Simon Frieder, Lionel Wong, Miri Zilka, Umang Bhatt, Thomas Lukasiewicz, Yuhuai Wu, Joshua~B. Tenenbaum, William Hart, Timothy Gowers, Wenda Li, Adrian Weller, and Mateja Jamnik.
\newblock Evaluating language models for mathematics through interactions, 2023.
\newblock URL \url{https://arxiv.org/abs/2306.01694}.

\bibitem[Lu et~al.(2024)Lu, Zhou, Ren, Wang, Shi, Pan, Zhan, and Li]{lu2024mathgeniegeneratingsyntheticdata}
Zimu Lu, Aojun Zhou, Houxing Ren, Ke~Wang, Weikang Shi, Junting Pan, Mingjie Zhan, and Hongsheng Li.
\newblock Mathgenie: Generating synthetic data with question back-translation for enhancing mathematical reasoning of llms, 2024.
\newblock URL \url{https://arxiv.org/abs/2402.16352}.

\bibitem[Nikolaiev and Anisimov(2022)]{Nikolaiev202294}
Andrii~D. Nikolaiev and Anatoliy~V. Anisimov.
\newblock Mathematical word problem solution evaluation via data preprocessing approach.
\newblock In \emph{8th International Scientific Conference "Information Technology and Implementation", IT and I 2021}, volume 3132, page 94 – 103, 2022.
\newblock URL \url{https://ceur-ws.org/Vol-3132/Paper_9.pdf}.

\bibitem[Kushman et~al.(2014)Kushman, Artzi, Zettlemoyer, and Barzilay]{kushman-etal-2014-learning}
Nate Kushman, Yoav Artzi, Luke Zettlemoyer, and Regina Barzilay.
\newblock Learning to automatically solve algebra word problems.
\newblock In Kristina Toutanova and Hua Wu, editors, \emph{Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 271--281, Baltimore, Maryland, June 2014. Association for Computational Linguistics.
\newblock \doi{10.3115/v1/P14-1026}.
\newblock URL \url{https://aclanthology.org/P14-1026/}.

\bibitem[Shi et~al.(2015)Shi, Wang, Lin, Liu, and Rui]{shi-etal-2015-automatically}
Shuming Shi, Yuehui Wang, Chin-Yew Lin, Xiaojiang Liu, and Yong Rui.
\newblock Automatically solving number word problems by semantic parsing and reasoning.
\newblock In Llu{\'i}s M{\`a}rquez, Chris Callison-Burch, and Jian Su, editors, \emph{Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing}, pages 1132--1142, Lisbon, Portugal, September 2015. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/D15-1135}.
\newblock URL \url{https://aclanthology.org/D15-1135/}.

\bibitem[Upadhyay and Chang(2015)]{Upadhyay2015DRAWAC}
Shyam Upadhyay and Ming-Wei Chang.
\newblock Draw: A challenging and diverse algebra word problem set, 2015.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:56036017}.

\bibitem[Koncel-Kedziorski et~al.(2015{\natexlab{b}})Koncel-Kedziorski, Hajishirzi, Sabharwal, Etzioni, and Ang]{koncel2015parsing}
Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish Sabharwal, Oren Etzioni, and Siena~Dumas Ang.
\newblock Parsing algebraic word problems into equations.
\newblock \emph{Transactions of the Association for Computational Linguistics}, 3:\penalty0 585--597, 2015{\natexlab{b}}.

\bibitem[Huang et~al.(2016)Huang, Shi, Lin, Yin, and Ma]{huang-etal-2016-well}
Danqing Huang, Shuming Shi, Chin-Yew Lin, Jian Yin, and Wei-Ying Ma.
\newblock How well do computers solve math word problems? large-scale dataset construction and evaluation.
\newblock In Katrin Erk and Noah~A. Smith, editors, \emph{Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 887--896, Berlin, Germany, August 2016. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P16-1084}.
\newblock URL \url{https://aclanthology.org/P16-1084/}.

\bibitem[Koncel-Kedziorski et~al.(2016)Koncel-Kedziorski, Roy, Amini, Kushman, and Hajishirzi]{koncel-kedziorski-etal-2016-mawps}
Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi.
\newblock {MAWPS}: A math word problem repository.
\newblock In Kevin Knight, Ani Nenkova, and Owen Rambow, editors, \emph{Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies}, pages 1152--1157, San Diego, California, June 2016. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/N16-1136}.
\newblock URL \url{https://aclanthology.org/N16-1136/}.

\bibitem[Wang et~al.(2017)Wang, Liu, and Shi]{wang-etal-2017-deep}
Yan Wang, Xiaojiang Liu, and Shuming Shi.
\newblock Deep neural solver for math word problems.
\newblock In Martha Palmer, Rebecca Hwa, and Sebastian Riedel, editors, \emph{Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing}, pages 845--854, Copenhagen, Denmark, September 2017. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/D17-1088}.
\newblock URL \url{https://aclanthology.org/D17-1088/}.

\bibitem[Zhao et~al.(2020)Zhao, Shang, Liu, Wang, and Liu]{zhao2020ape210klargescaletemplaterichdataset}
Wei Zhao, Mingyue Shang, Yang Liu, Liang Wang, and Jingming Liu.
\newblock Ape210k: A large-scale and template-rich dataset of math word problems, 2020.
\newblock URL \url{https://arxiv.org/abs/2009.11506}.

\bibitem[Patel et~al.(2021{\natexlab{a}})Patel, Bhattamishra, and Goyal]{patel-etal-2021-nlp}
Arkil Patel, Satwik Bhattamishra, and Navin Goyal.
\newblock Are {NLP} models really able to solve simple math word problems?
\newblock In Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek Hakkani-Tur, Iz~Beltagy, Steven Bethard, Ryan Cotterell, Tanmoy Chakraborty, and Yichao Zhou, editors, \emph{Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}, pages 2080--2094, Online, June 2021{\natexlab{a}}. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2021.naacl-main.168}.
\newblock URL \url{https://aclanthology.org/2021.naacl-main.168/}.

\bibitem[Hendrycks et~al.(2021{\natexlab{b}})Hendrycks, Burns, Basart, Zou, Mazeika, Song, and Steinhardt]{hendrycks2021measuringmassivemultitasklanguage}
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.
\newblock Measuring massive multitask language understanding, 2021{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2009.03300}.

\bibitem[Mirzadeh et~al.(2024)Mirzadeh, Alizadeh, Shahrokhi, Tuzel, Bengio, and Farajtabar]{mirzadeh2024gsmsymbolicunderstandinglimitationsmathematical}
Iman Mirzadeh, Keivan Alizadeh, Hooman Shahrokhi, Oncel Tuzel, Samy Bengio, and Mehrdad Farajtabar.
\newblock Gsm-symbolic: Understanding the limitations of mathematical reasoning in large language models, 2024.
\newblock URL \url{https://arxiv.org/abs/2410.05229}.

\bibitem[He et~al.(2024)He, Luo, Bai, Hu, Thai, Shen, Hu, Han, Huang, Zhang, Liu, Qi, Liu, and Sun]{he2024olympiadbenchchallengingbenchmarkpromoting}
Chaoqun He, Renjie Luo, Yuzhuo Bai, Shengding Hu, Zhen~Leng Thai, Junhao Shen, Jinyi Hu, Xu~Han, Yujie Huang, Yuxiang Zhang, Jie Liu, Lei Qi, Zhiyuan Liu, and Maosong Sun.
\newblock Olympiadbench: A challenging benchmark for promoting agi with olympiad-level bilingual multimodal scientific problems, 2024.
\newblock URL \url{https://arxiv.org/abs/2402.14008}.

\bibitem[Gao et~al.(2024)Gao, Song, Yang, Cai, Miao, Dong, Li, Ma, Chen, Xu, Tang, Wang, Zan, Quan, Zhang, Sha, Zhang, Ren, Liu, and Chang]{gao2024omnimathuniversalolympiadlevel}
Bofei Gao, Feifan Song, Zhe Yang, Zefan Cai, Yibo Miao, Qingxiu Dong, Lei Li, Chenghao Ma, Liang Chen, Runxin Xu, Zhengyang Tang, Benyou Wang, Daoguang Zan, Shanghaoran Quan, Ge~Zhang, Lei Sha, Yichang Zhang, Xuancheng Ren, Tianyu Liu, and Baobao Chang.
\newblock Omni-math: A universal olympiad level mathematic benchmark for large language models, 2024.
\newblock URL \url{https://arxiv.org/abs/2410.07985}.

\bibitem[Mao et~al.(2024)Mao, Kim, and Zhou]{mao2024champcompetitionleveldatasetfinegrained}
Yujun Mao, Yoon Kim, and Yilun Zhou.
\newblock Champ: A competition-level dataset for fine-grained analyses of llms' mathematical reasoning capabilities, 2024.
\newblock URL \url{https://arxiv.org/abs/2401.06961}.

\bibitem[Ye et~al.(2024)Ye, Xu, Li, and Allen-Zhu]{ye2024physicslanguagemodels21}
Tian Ye, Zicheng Xu, Yuanzhi Li, and Zeyuan Allen-Zhu.
\newblock Physics of language models: Part 2.1, grade-school math and the hidden reasoning process, 2024.
\newblock URL \url{https://arxiv.org/abs/2407.20311}.

\bibitem[Beeching et~al.(2024)Beeching, Huang, Jiang, Li, Lipkin, Qina, Rasul, Shen, Soletskyi, and Tunstall]{numina_math_7b}
Edward Beeching, Shengyi~Costa Huang, Albert Jiang, Jia Li, Benjamin Lipkin, Zihan Qina, Kashif Rasul, Ziju Shen, Roman Soletskyi, and Lewis Tunstall.
\newblock Numinamath 7b tir.
\newblock \url{https://huggingface.co/AI-MO/NuminaMath-7B-TIR}, 2024.

\bibitem[Patel et~al.(2021{\natexlab{b}})Patel, Bhattamishra, and Goyal]{patel2021nlpmodelsreallyable}
Arkil Patel, Satwik Bhattamishra, and Navin Goyal.
\newblock Are nlp models really able to solve simple math word problems?, 2021{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2103.07191}.

\bibitem[Wang et~al.(2024)Wang, Ma, Zhang, Ni, Chandra, Guo, Ren, Arulraj, He, Jiang, Li, Ku, Wang, Zhuang, Fan, Yue, and Chen]{wang2024mmluprorobustchallengingmultitask}
Yubo Wang, Xueguang Ma, Ge~Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang Guo, Weiming Ren, Aaran Arulraj, Xuan He, Ziyan Jiang, Tianle Li, Max Ku, Kai Wang, Alex Zhuang, Rongqi Fan, Xiang Yue, and Wenhu Chen.
\newblock Mmlu-pro: A more robust and challenging multi-task language understanding benchmark, 2024.
\newblock URL \url{https://arxiv.org/abs/2406.01574}.

\bibitem[Mittal et~al.(2024)Mittal, Kartik, Mausam, and Singla]{mittal2024puzzlebenchllmssolvechallenging}
Chinmay Mittal, Krishna Kartik, Mausam, and Parag Singla.
\newblock Puzzlebench: Can llms solve challenging first-order combinatorial reasoning problems?, 2024.
\newblock URL \url{https://arxiv.org/abs/2402.02611}.

\bibitem[Golchin and Surdeanu(2024)]{golchin2024timetravelllmstracing}
Shahriar Golchin and Mihai Surdeanu.
\newblock Time travel in llms: Tracing data contamination in large language models, 2024.
\newblock URL \url{https://arxiv.org/abs/2308.08493}.

\bibitem[Zhang et~al.(2024)Zhang, Da, Lee, Robinson, Wu, Song, Zhao, Raja, Slack, Lyu, Hendryx, Kaplan, Lunati, and Yue]{zhang2024carefulexaminationlargelanguage}
Hugh Zhang, Jeff Da, Dean Lee, Vaughn Robinson, Catherine Wu, Will Song, Tiffany Zhao, Pranav Raja, Dylan Slack, Qin Lyu, Sean Hendryx, Russell Kaplan, Michele Lunati, and Summer Yue.
\newblock A careful examination of large language model performance on grade school arithmetic, 2024.
\newblock URL \url{https://arxiv.org/abs/2405.00332}.

\bibitem[Zheng et~al.(2023)Zheng, Chiang, Sheng, Zhuang, Wu, Zhuang, Lin, Li, Li, Xing, Zhang, Gonzalez, and Stoica]{zheng2023judgingllmasajudgemtbenchchatbot}
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi~Lin, Zhuohan Li, Dacheng Li, Eric~P. Xing, Hao Zhang, Joseph~E. Gonzalez, and Ion Stoica.
\newblock Judging llm-as-a-judge with mt-bench and chatbot arena, 2023.
\newblock URL \url{https://arxiv.org/abs/2306.05685}.

\bibitem[Nikolaiev et~al.(2024)Nikolaiev, Stathopoulos, and Teufel]{nikolaiev2024can}
Andrii Nikolaiev, Yiannos Stathopoulos, and Simone Teufel.
\newblock Can language models rival mathematics students? evaluating mathematical reasoning through textual manipulation and human experiments, 2024.
\newblock URL \url{https://arxiv.org/abs/2412.11908}.

\bibitem[Anisimov and Derevyanchenko(2005)]{Anisimov2005}
A.~V. Anisimov and A.~V. Derevyanchenko.
\newblock The system parcs-java for parallel computations on computer networks.
\newblock \emph{Cybernetics and Systems Analysis}, 41\penalty0 (1):\penalty0 17--26, Jan 2005.
\newblock ISSN 1573-8337.
\newblock \doi{10.1007/s10559-005-0037-4}.
\newblock URL \url{https://doi.org/10.1007/s10559-005-0037-4}.

\bibitem[Власенко et~al.(2019)Власенко, Картавих, Ніколаєв, and Горбенко]{vlasenko2019methodology}
О.В. Власенко, В.Ю. Картавих, А.Д. Ніколаєв, and В.І. Горбенко.
\newblock Методика визначення опорної матриці моніторингу домена управління інформаційної мережі спеціального призначення.
\newblock \emph{Системи і технології зв’язку, інформатизації та кібербезпеки. Збірник наукових праць ВІТІ, випуск 4}, pages 46--57, 2019.

\bibitem[Team(2024)]{grattafiori2024llama3herdmodels}
Llama Team.
\newblock The llama 3 herd of models, 2024.
\newblock URL \url{https://arxiv.org/abs/2407.21783}.

\bibitem[Jacob et~al.(2017)Jacob, Kligys, Chen, Zhu, Tang, Howard, Adam, and Kalenichenko]{jacob2017quantizationtrainingneuralnetworks}
Benoit Jacob, Skirmantas Kligys, Bo~Chen, Menglong Zhu, Matthew Tang, Andrew Howard, Hartwig Adam, and Dmitry Kalenichenko.
\newblock Quantization and training of neural networks for efficient integer-arithmetic-only inference, 2017.
\newblock URL \url{https://arxiv.org/abs/1712.05877}.

\bibitem[Nikolaiev and Derevianchenko(2024)]{nikolaiev2024comparison}
Andrii~D. Nikolaiev and Oleksandr~V. Derevianchenko.
\newblock Comparison of problem-solving performance across mathematical domains with large language models.
\newblock \emph{Shtuchnyy intelekt}, pages 96--104, 2024.
\newblock URL \url{https://doi.org/10.15407/jai2024.04.096}.

\bibitem[Ніколаєв and Анісімов(2025)]{nikolaiev2025synth}
Андрій~Д. Ніколаєв and Анатолій~В. Анісімов.
\newblock Нейромережеві методи відбору та генерації синтетичних варіацій комбінаторних задач.
\newblock \emph{Cybernetics and Systems Analysis}, 41\penalty0 (1):\penalty0 22–32, 2025.
\newblock \doi{10.34229/KCA2522-9664.25.3.3}.
\newblock URL \url{https://doi.org/10.34229/KCA2522-9664.25.3.3}.

\end{thebibliography}
